{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the required libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data set and investigating it ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>Termid</th>\n",
       "      <th>RegdNo</th>\n",
       "      <th>Course</th>\n",
       "      <th>Grade</th>\n",
       "      <th>CA_100</th>\n",
       "      <th>MTT_50</th>\n",
       "      <th>ETT_100</th>\n",
       "      <th>ETP_100</th>\n",
       "      <th>Course_Att</th>\n",
       "      <th>...</th>\n",
       "      <th>CA_3</th>\n",
       "      <th>CA_4</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>ScholarType</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Medium</th>\n",
       "      <th>CourseType</th>\n",
       "      <th>ProgramType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>392</td>\n",
       "      <td>418192</td>\n",
       "      <td>1198776</td>\n",
       "      <td>TJZ267</td>\n",
       "      <td>O</td>\n",
       "      <td>89.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>171</td>\n",
       "      <td>67</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>East</td>\n",
       "      <td>Male</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>393</td>\n",
       "      <td>418192</td>\n",
       "      <td>1198776</td>\n",
       "      <td>TJZ268</td>\n",
       "      <td>A</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>171</td>\n",
       "      <td>67</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>East</td>\n",
       "      <td>Male</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>394</td>\n",
       "      <td>418192</td>\n",
       "      <td>1198776</td>\n",
       "      <td>TJZ269</td>\n",
       "      <td>B+</td>\n",
       "      <td>74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>171</td>\n",
       "      <td>67</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>East</td>\n",
       "      <td>Male</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>593</td>\n",
       "      <td>218192</td>\n",
       "      <td>1273776</td>\n",
       "      <td>TJZ20</td>\n",
       "      <td>O</td>\n",
       "      <td>90.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>165</td>\n",
       "      <td>76</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>North</td>\n",
       "      <td>Female</td>\n",
       "      <td>English</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>594</td>\n",
       "      <td>218192</td>\n",
       "      <td>1273776</td>\n",
       "      <td>TJZ21</td>\n",
       "      <td>B+</td>\n",
       "      <td>77.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>165</td>\n",
       "      <td>76</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>North</td>\n",
       "      <td>Female</td>\n",
       "      <td>English</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  Termid   RegdNo  Course Grade  CA_100  MTT_50  ETT_100  ETP_100  \\\n",
       "0  392  418192  1198776  TJZ267     O    89.0     NaN      NaN     75.0   \n",
       "1  393  418192  1198776  TJZ268     A    87.0     NaN      NaN     56.0   \n",
       "2  394  418192  1198776  TJZ269    B+    74.0     NaN      NaN     57.0   \n",
       "3  593  218192  1273776   TJZ20     O    90.0    39.0     85.0      NaN   \n",
       "4  594  218192  1273776   TJZ21    B+    77.0    30.0     49.0      NaN   \n",
       "\n",
       "   Course_Att  ...  CA_3  CA_4  Height  Weight  ScholarType  Direction  \\\n",
       "0         NaN  ...   1.0   3.0     171      67  Day Scholar       East   \n",
       "1        99.0  ...  11.0   6.0     171      67  Day Scholar       East   \n",
       "2       100.0  ...   3.0   0.0     171      67  Day Scholar       East   \n",
       "3        92.0  ...   1.0   1.0     165      76  Day Scholar      North   \n",
       "4        85.0  ...   2.0   1.0     165      76  Day Scholar      North   \n",
       "\n",
       "   Gender    Medium CourseType ProgramType  \n",
       "0    Male  Regional     Theory          UG  \n",
       "1    Male  Regional     Theory          UG  \n",
       "2    Male  Regional     Theory          UG  \n",
       "3  Female   English     Theory          UG  \n",
       "4  Female   English     Theory          UG  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"My_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3917 entries, 0 to 3916\n",
      "Data columns (total 23 columns):\n",
      "0              3917 non-null int64\n",
      "Termid         3917 non-null int64\n",
      "RegdNo         3917 non-null int64\n",
      "Course         3917 non-null object\n",
      "Grade          3917 non-null object\n",
      "CA_100         3794 non-null float64\n",
      "MTT_50         2574 non-null float64\n",
      "ETT_100        2601 non-null float64\n",
      "ETP_100        1316 non-null float64\n",
      "Course_Att     3680 non-null float64\n",
      "MHRDName       3917 non-null object\n",
      "CA_1           3794 non-null float64\n",
      "CA_2           3794 non-null float64\n",
      "CA_3           3794 non-null float64\n",
      "CA_4           3794 non-null float64\n",
      "Height         3917 non-null int64\n",
      "Weight         3917 non-null int64\n",
      "ScholarType    3917 non-null object\n",
      "Direction      3917 non-null object\n",
      "Gender         3917 non-null object\n",
      "Medium         3917 non-null object\n",
      "CourseType     3917 non-null object\n",
      "ProgramType    3917 non-null object\n",
      "dtypes: float64(9), int64(5), object(9)\n",
      "memory usage: 704.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding and deleting duplicate rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data.duplicated())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since the data has no duplicates we will not drop the duplicates "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will see numbers of unique values in each columns and also see Correlation between the columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3917\n",
      "4\n",
      "545\n",
      "100\n",
      "12\n",
      "95\n",
      "49\n",
      "85\n",
      "86\n",
      "92\n",
      "1\n",
      "93\n",
      "81\n",
      "64\n",
      "62\n",
      "35\n",
      "61\n",
      "2\n",
      "4\n",
      "2\n",
      "3\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "allcolumns=data.columns\n",
    "for item in allcolumns:\n",
    "    print(data[item].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   0    Termid    RegdNo    CA_100    MTT_50   ETT_100  \\\n",
      "0           1.000000 -0.029304  0.999907 -0.038962 -0.024238 -0.047602   \n",
      "Termid     -0.029304  1.000000 -0.028428  0.055018  0.071740 -0.002854   \n",
      "RegdNo      0.999907 -0.028428  1.000000 -0.039575 -0.024678 -0.048274   \n",
      "CA_100     -0.038962  0.055018 -0.039575  1.000000  0.542311  0.572094   \n",
      "MTT_50     -0.024238  0.071740 -0.024678  0.542311  1.000000  0.566105   \n",
      "ETT_100    -0.047602 -0.002854 -0.048274  0.572094  0.566105  1.000000   \n",
      "ETP_100    -0.099069  0.242622 -0.100140  0.658175       NaN       NaN   \n",
      "Course_Att -0.058904 -0.008296 -0.059951  0.589069  0.460177  0.472513   \n",
      "CA_1        0.012194  0.021079  0.011808  0.479819  0.261051  0.306289   \n",
      "CA_2       -0.022118  0.026489 -0.022269  0.328831  0.183610  0.173556   \n",
      "CA_3       -0.046653  0.036336 -0.046710  0.264453  0.140331  0.147100   \n",
      "CA_4       -0.025801 -0.009849 -0.025942  0.254163  0.140555  0.118932   \n",
      "Height     -0.042665  0.037840 -0.042050  0.016805  0.032626  0.012540   \n",
      "Weight     -0.027958 -0.022060 -0.027950 -0.043250 -0.006215  0.001579   \n",
      "\n",
      "             ETP_100  Course_Att      CA_1      CA_2      CA_3      CA_4  \\\n",
      "0          -0.099069   -0.058904  0.012194 -0.022118 -0.046653 -0.025801   \n",
      "Termid      0.242622   -0.008296  0.021079  0.026489  0.036336 -0.009849   \n",
      "RegdNo     -0.100140   -0.059951  0.011808 -0.022269 -0.046710 -0.025942   \n",
      "CA_100      0.658175    0.589069  0.479819  0.328831  0.264453  0.254163   \n",
      "MTT_50           NaN    0.460177  0.261051  0.183610  0.140331  0.140555   \n",
      "ETT_100          NaN    0.472513  0.306289  0.173556  0.147100  0.118932   \n",
      "ETP_100     1.000000    0.573172  0.294252  0.225197  0.178626  0.147030   \n",
      "Course_Att  0.573172    1.000000  0.274029  0.206688  0.162743  0.149543   \n",
      "CA_1        0.294252    0.274029  1.000000 -0.382405 -0.287118 -0.295143   \n",
      "CA_2        0.225197    0.206688 -0.382405  1.000000 -0.025255 -0.014907   \n",
      "CA_3        0.178626    0.162743 -0.287118 -0.025255  1.000000  0.197836   \n",
      "CA_4        0.147030    0.149543 -0.295143 -0.014907  0.197836  1.000000   \n",
      "Height      0.035277   -0.017728  0.010905  0.003668 -0.001940  0.007495   \n",
      "Weight      0.027205   -0.060470 -0.011769 -0.021186 -0.028570 -0.002215   \n",
      "\n",
      "              Height    Weight  \n",
      "0          -0.042665 -0.027958  \n",
      "Termid      0.037840 -0.022060  \n",
      "RegdNo     -0.042050 -0.027950  \n",
      "CA_100      0.016805 -0.043250  \n",
      "MTT_50      0.032626 -0.006215  \n",
      "ETT_100     0.012540  0.001579  \n",
      "ETP_100     0.035277  0.027205  \n",
      "Course_Att -0.017728 -0.060470  \n",
      "CA_1        0.010905 -0.011769  \n",
      "CA_2        0.003668 -0.021186  \n",
      "CA_3       -0.001940 -0.028570  \n",
      "CA_4        0.007495 -0.002215  \n",
      "Height      1.000000  0.024414  \n",
      "Weight      0.024414  1.000000  \n"
     ]
    }
   ],
   "source": [
    "correl=data.corr()\n",
    "print(correl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have rows with null values so we will drop the rows with nan values in them ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fillna(data.mean(),axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0  CA_100    MTT_50   ETT_100    ETP_100  Course_Att\n",
      "0       392    89.0  24.22028  47.85198  75.000000   81.747283\n",
      "1       393    87.0  24.22028  47.85198  56.000000   99.000000\n",
      "2       394    74.0  24.22028  47.85198  57.000000  100.000000\n",
      "3       593    90.0  39.00000  85.00000  64.837386   92.000000\n",
      "4       594    77.0  30.00000  49.00000  64.837386   85.000000\n",
      "...     ...     ...       ...       ...        ...         ...\n",
      "3912  65041    71.0  24.22028  47.85198  50.000000   74.000000\n",
      "3913  65042    80.0  24.22028  47.85198  76.000000   61.000000\n",
      "3914  65043    52.0  27.00000  58.00000  64.837386   90.000000\n",
      "3915  65044    65.0  20.00000  45.00000  64.837386   90.000000\n",
      "3916  65045    41.0  25.00000  36.00000  64.837386   80.000000\n",
      "\n",
      "[3917 rows x 6 columns]\n",
      "0        O\n",
      "1        A\n",
      "2       B+\n",
      "3        O\n",
      "4       B+\n",
      "        ..\n",
      "3912    B+\n",
      "3913    B+\n",
      "3914    B+\n",
      "3915     C\n",
      "3916     C\n",
      "Name: Grade, Length: 3917, dtype: object\n"
     ]
    }
   ],
   "source": [
    "x=data.drop([\"Grade\",\"RegdNo\",\"Termid\",\"Course\",\"MHRDName\",\"Height\",\"Weight\",\"ScholarType\",\"CA_1\",\"CA_2\",\"CA_3\",\"CA_4\",\"Direction\",\"Gender\",\"Medium\",\"CourseType\",\"ProgramType\"],axis=1)\n",
    "y=data[\"Grade\"]\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The grades are categorial and are objects (string) so we need to convert them in labels to do so we will do Data Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mark_mapping={'O':0,'A+':1,'A':2,'B+':3,'B':4,'C':5,'D':6,'E':7,'F':8,'M':9,'I':10,'R':11}\n",
    "y=y.replace(mark_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0\n",
      "1       2\n",
      "2       3\n",
      "3       0\n",
      "4       3\n",
      "       ..\n",
      "3912    3\n",
      "3913    3\n",
      "3914    3\n",
      "3915    5\n",
      "3916    5\n",
      "Name: Grade, Length: 3917, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.astype(np.uint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We now make run the predictive algorithm to predict the grade and if grade is below 5 the student is FAIL  and if the grade is 5 or above we will get PASS as a result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-6.76307345e-01  2.52344416e-01  3.15437604e-01  1.24221681e-01\n",
      "   7.54351514e-03 -8.46514177e-01]\n",
      " [-8.76160125e-03 -7.35389326e-01  6.54838727e-01  8.59557970e-01\n",
      "   7.54351514e-03  1.60138032e-02]\n",
      " [ 1.65649391e-01 -5.87229265e-01 -1.38156801e+00 -1.06362925e+00\n",
      "   7.54351514e-03 -1.27777817e+00]\n",
      " ...\n",
      " [-4.75879243e-01 -3.05656362e+00 -2.73917250e+00 -2.70399482e+00\n",
      "   7.54351514e-03 -2.44835186e+00]\n",
      " [-3.81616819e-01  5.48664538e-01  9.57542103e-04  2.72036897e-03\n",
      "   5.86525647e-01  1.12497835e+00]\n",
      " [-9.33020826e-01 -9.33623941e-02  9.57542103e-04  2.72036897e-03\n",
      "   5.86525647e-01 -1.15455988e+00]]\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3, random_state=101)\n",
    "scale=StandardScaler()\n",
    "x_train=scale.fit_transform(x_train)\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\niharika\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\niharika\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test=scale.fit_transform(x_test)\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41496598639455784\n"
     ]
    }
   ],
   "source": [
    "predictedvalues=model.predict(x_test)\n",
    "print(accuracy_score(y_test,predictedvalues))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have only used logistic regression in this predictor, we can also use other ones for better prediction values like \n",
    "#### 1.RandomForestClassifier\n",
    "#### 2.AdaBoostClassifier\n",
    "#### 3.GradientBoostingClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\niharika\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5790816326530612\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "predictedvalues=model.predict(x_test)\n",
    "print(accuracy_score(y_test,predictedvalues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3129251700680272\n"
     ]
    }
   ],
   "source": [
    "model = AdaBoostClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "predictedvalues=model.predict(x_test)\n",
    "print(accuracy_score(y_test,predictedvalues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5986394557823129\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "predictedvalues=model.predict(x_test)\n",
    "print(accuracy_score(y_test,predictedvalues))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check for any value whether it is pass or fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_mapping = {mark_mapping[i]:i for i in mark_mapping}\n",
    "final=score_mapping[model.predict(x.values[0].reshape(-1,6))[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final grade is \n",
      "O\n",
      "PASS\n"
     ]
    }
   ],
   "source": [
    "print(\"Final grade is \")\n",
    "print(final)\n",
    "\n",
    "Pass_garde=['O','A','A+','B','B+','C','D']\n",
    "if(final in Pass_garde):\n",
    "    print(\"PASS\")\n",
    "else :\n",
    "    print(\"FAIL\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
